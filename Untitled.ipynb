{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import pytesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "import os\n",
    "from PIL import Image\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open(r\"example2.jpg\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"example2.jpg\"\n",
    "size = 1200, 540\n",
    "file_parts = os.path.splitext(filename)\n",
    "\n",
    "outfile = file_parts[0] + '_250x250' + file_parts[1]\n",
    "try:\n",
    "    img = Image.open(filename)\n",
    "    img = img.resize(size, Image.ANTIALIAS)\n",
    "    img.save(outfile, 'PNG')\n",
    "except IOError as e:\n",
    "    print(\"An exception occured '%s'\" %e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "image = cv2.imread(\"example1_250x250.jpg\")\n",
    "example = cv2.imread(\"ifsc_exmple.jpg\")\n",
    "y=100\n",
    "x=0\n",
    "h=100\n",
    "w=365\n",
    "##### left = 50\n",
    "##### top = 0\n",
    "##### right = 365\n",
    "##### bottom = 100\n",
    "# image = image[0:100, 100:365]\n",
    "bank_name = image[0:150, 100:405]\n",
    "address_ifsc = image[0:100, 350:700]\n",
    "# codes = image[430:900, 0:1000]\n",
    "# codes = image[1100:1700, 600:2000]\n",
    "# account_number  = image[250:300, 100:450]\n",
    "# account_number  = image[240:300, 80:450]\n",
    "cv2.imshow('Image', address_ifsc)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pytesseract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-685085220742>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbank_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pytesseract' is not defined"
     ]
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(bank_name)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pytesseract.image_to_string(bank_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text = str(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'account_number' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-58cd5b5a90d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpytesseract\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccount_number\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\D'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'account_number' is not defined"
     ]
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(account_number)\n",
    "text = re.sub('\\D',\"\",text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_all_banks = [\"State Bank of India\", \"Punjab National Bank\", \"Union Bank of India\", \n",
    "                    \"Canara Bank\", \"Bank of Baroda\", \"Bank of India\", \"Central Bank of India\", \n",
    "                    \"Indian Bank\", \"Indian Overseas Bank\", \"ICICI Bank\", \"HDFC Bank, Axis Bank\", \n",
    "                    \"IDBI Bank\", \"Yes Bank\", \"Kotak Mahindra Bank\", \"IndusInd Bank\", \n",
    "                    \"Federal Bank\", \"IDFC First Bank\", \"Jammu and Kashmir Bank\"]\n",
    "print(len(list_of_all_banks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "similarity_index = 0 \n",
    "for i in range(len(list_of_all_banks)):\n",
    "    current_similarity_index = SequenceMatcher(None,text,list_of_all_banks[i]).ratio()\n",
    "    if similarity_index < current_similarity_index:\n",
    "        similarity_index  = current_similarity_index\n",
    "        bank_name = list_of_all_banks[i]\n",
    "print(bank_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_ifsc = str(pytesseract.image_to_string(address_ifsc))\n",
    "print(address_ifsc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = address_ifsc.split(\":\")\n",
    "print(str(words[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'address_ifsc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-e72e6f5392c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maddress_ifsc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\":\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'address_ifsc' is not defined"
     ]
    }
   ],
   "source": [
    "words = address_ifsc.split(\":\")\n",
    "print(words)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(words)):\n",
    "    words[i]= words[i].replace(\"\\n\", \"\");\n",
    "    words[i]= words[i].replace(\"\\x0c\", \"\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(words)             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = str(pytesseract.image_to_string(codes))\n",
    "print(codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from skimage.segmentation import clear_border\n",
    "from imutils import contours\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_digits_and_symbols(image, charCnts, minW=5, minH=15):\n",
    "\t# grab the internal Python iterator for the list of character\n",
    "\t# contours, then  initialize the character ROI and location\n",
    "\t# lists, respectively\n",
    "\tcharIter = charCnts.__iter__()\n",
    "\trois = []\n",
    "\tlocs = []\n",
    "\t# keep looping over the character contours until we reach the end\n",
    "\t# of the list\n",
    "\twhile True:\n",
    "\t\ttry:\n",
    "\t\t\t# grab the next character contour from the list, compute\n",
    "\t\t\t# its bounding box, and initialize the ROI\n",
    "\t\t\tc = next(charIter)\n",
    "\t\t\t(cX, cY, cW, cH) = cv2.boundingRect(c)\n",
    "\t\t\troi = None\n",
    "\t\t\t# check to see if the width and height are sufficiently\n",
    "\t\t\t# large, indicating that we have found a digit\n",
    "\t\t\tif cW >= minW and cH >= minH:\n",
    "\t\t\t\t# extract the ROI\n",
    "\t\t\t\troi = image[cY:cY + cH, cX:cX + cW]\n",
    "\t\t\t\trois.append(roi)\n",
    "\t\t\t\tlocs.append((cX, cY, cX + cW, cY + cH))\n",
    "                \t\t\t# otherwise, we are examining one of the special symbols\n",
    "\t\t\telse:\n",
    "\t\t\t\t# MICR symbols include three separate parts, so we\n",
    "\t\t\t\t# need to grab the next two parts from our iterator,\n",
    "\t\t\t\t# followed by initializing the bounding box\n",
    "\t\t\t\t# coordinates for the symbol\n",
    "\t\t\t\tparts = [c, next(charIter), next(charIter)]\n",
    "\t\t\t\t(sXA, sYA, sXB, sYB) = (np.inf, np.inf, -np.inf,\n",
    "\t\t\t\t\t-np.inf)\n",
    "\t\t\t\t# loop over the parts\n",
    "\t\t\t\tfor p in parts:\n",
    "\t\t\t\t\t# compute the bounding box for the part, then\n",
    "\t\t\t\t\t# update our bookkeeping variables\n",
    "\t\t\t\t\t(pX, pY, pW, pH) = cv2.boundingRect(p)\n",
    "\t\t\t\t\tsXA = min(sXA, pX)\n",
    "\t\t\t\t\tsYA = min(sYA, pY)\n",
    "\t\t\t\t\tsXB = max(sXB, pX + pW)\n",
    "\t\t\t\t\tsYB = max(sYB, pY + pH)\n",
    "\t\t\t\t# extract the ROI\n",
    "\t\t\t\troi = image[sYA:sYB, sXA:sXB]\n",
    "\t\t\t\trois.append(roi)\n",
    "\t\t\t\tlocs.append((sXA, sYA, sXB, sYB))\n",
    "                \t\t# we have reached the end of the iterator; gracefully break\n",
    "\t\t# from the loop\n",
    "\t\texcept StopIteration:\n",
    "\t\t\tbreak\n",
    "\t# return a tuple of the ROIs and locations\n",
    "\treturn (rois, locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "charNames = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\",\n",
    "\t\"T\", \"U\", \"A\", \"D\"]\n",
    "# load the reference MICR image from disk, convert it to grayscale,\n",
    "# and threshold it, such that the digits appear as *white* on a\n",
    "# *black* background\n",
    "ref = cv2.imread(\"kotak_mahindra_example.jpg\")\n",
    "ref = cv2.cvtColor(ref, cv2.COLOR_BGR2GRAY)\n",
    "ref = imutils.resize(ref, width=400)\n",
    "ref = cv2.threshold(ref, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the MICR image (i.e,. the outlines of the\n",
    "# characters) and sort them from left to right\n",
    "refCnts = cv2.findContours(ref.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "refCnts = refCnts[1] if imutils.is_cv3() else refCnts[0]\n",
    "refCnts = contours.sort_contours(refCnts, method=\"left-to-right\")[0]\n",
    "\n",
    "refROIs = extract_digits_and_symbols(ref, refCnts,\n",
    "\tminW=10, minH=20)[0]\n",
    "chars = {}\n",
    "# loop over the reference ROIs\n",
    "for (name, roi) in zip(charNames, refROIs):\n",
    "\t# resize the ROI to a fixed size, then update the characters\n",
    "\t# dictionary, mapping the character name to the ROI\n",
    "\troi = cv2.resize(roi, (36, 36)) \n",
    "\tchars[name] = roi\n",
    "# initialize a rectangular kernel (wider than it is tall) along with\n",
    "# an empty list to store the output of the check OCR\n",
    "rectKernel = cv2.getStructuringElement(cv2.MORPH_RECT, (17, 7))\n",
    "output = []\n",
    "# load the input image, grab its dimensions, and apply array slicing\n",
    "# to keep only the bottom 20% of the image (that's where the account\n",
    "# information is)\n",
    "image = cv2.imread(\"kotak_mahindra_example.jpg\")\n",
    "(h, w,) = image.shape[:2]\n",
    "delta = int(h - (h * 0.2))\n",
    "bottom = image[delta:h, 0:w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the bottom image to grayscale, then apply a blackhat\n",
    "# morphological operator to find dark regions against a light\n",
    "# background (i.e., the routing and account numbers)\n",
    "gray = cv2.cvtColor(bottom, cv2.COLOR_BGR2GRAY)\n",
    "blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the Scharr gradient of the blackhat image, then scale\n",
    "# the rest back into the range [0, 255]\n",
    "gradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F, dx=1, dy=0,\n",
    "\tksize=-1)\n",
    "gradX = np.absolute(gradX)\n",
    "(minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "gradX = (255 * ((gradX - minVal) / (maxVal - minVal)))\n",
    "gradX = gradX.astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a closing operation using the rectangular kernel to help\n",
    "# cloes gaps in between rounting and account digits, then apply\n",
    "# Otsu's thresholding method to binarize the image\n",
    "gradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKernel)\n",
    "thresh = cv2.threshold(gradX, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any pixels that are touching the borders of the image (this\n",
    "# simply helps us in the next step when we prune contours)\n",
    "thresh = clear_border(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the thresholded image, then initialize the\n",
    "# list of group locations\n",
    "groupCnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "groupCnts = imutils.grab_contours(groupCnts)\n",
    "groupLocs = []\n",
    "# loop over the group contours\n",
    "for (i, c) in enumerate(groupCnts):\n",
    "\t# compute the bounding box of the contour\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\t# only accept the contour region as a grouping of characters if\n",
    "\t# the ROI is sufficiently large\n",
    "\tif w > 50 and h > 15:\n",
    "\t\tgroupLocs.append((x, y, w, h))\n",
    "# sort the digit locations from left-to-right\n",
    "groupLocs = sorted(groupLocs, key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the group locations\n",
    "for (gX, gY, gW, gH) in groupLocs:\n",
    "\t# initialize the group output of characters\n",
    "\tgroupOutput = []\n",
    "\t# extract the group ROI of characters from the grayscale\n",
    "\t# image, then apply thresholding to segment the digits from\n",
    "\t# the background of the credit card\n",
    "\tgroup = gray[gY - 5:gY + gH + 5, gX - 5:gX + gW + 5]\n",
    "\tgroup = cv2.threshold(group, 0, 255,\n",
    "\t\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "\tcv2.imshow(\"Group\", group)\n",
    "\tcv2.waitKey(0)\n",
    "\tcv2.destroyAllWindows()\n",
    "\t# find character contours in the group, then sort them from\n",
    "\t# left to right\n",
    "\tcharCnts = cv2.findContours(group.copy(), cv2.RETR_EXTERNAL,\n",
    "\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcharCnts = imutils.grab_contours(charCnts)\n",
    "\tcharCnts = contours.sort_contours(charCnts,\n",
    "\t\tmethod=\"left-to-right\")[0]\n",
    "    \t# find the characters and symbols in the group\n",
    "\t(rois, locs) = extract_digits_and_symbols(group, charCnts)\n",
    "\t# loop over the ROIs from the group\n",
    "\tfor roi in rois:\n",
    "\t\t# initialize the list of template matching scores and\n",
    "\t\t# resize the ROI to a fixed size\n",
    "\t\tscores = []\n",
    "\t\troi = cv2.resize(roi, (36, 36))\n",
    "\t\t# loop over the reference character name and corresponding\n",
    "\t\t# ROI\n",
    "\t\tfor charName in charNames:\n",
    "\t\t\t# apply correlation-based template matching, take the\n",
    "\t\t\t# score, and update the scores list\n",
    "\t\t\tresult = cv2.matchTemplate(roi, chars[charName],\n",
    "\t\t\t\tcv2.TM_CCOEFF)\n",
    "\t\t\t(_, score, _, _) = cv2.minMaxLoc(result)\n",
    "\t\t\tscores.append(score)\n",
    "\t\t# the classification for the character ROI will be the\n",
    "\t\t# reference character name with the *largest* template\n",
    "\t\t# matching score\n",
    "\t\tgroupOutput.append(charNames[np.argmax(scores)])\n",
    "        # draw (padded) bounding box surrounding the group along with\n",
    "\t# the OCR output of the group\n",
    "\tcv2.rectangle(image, (gX - 10, gY + delta - 10),\n",
    "\t\t(gX + gW + 10, gY + gY + delta), (0, 0, 255), 2)\n",
    "\tcv2.putText(image, \"\".join(groupOutput),\n",
    "\t\t(gX - 10, gY + delta - 25), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "\t\t0.95, (0, 0, 255), 3)\n",
    "\t# add the group output to the overall check OCR output\n",
    "\toutput.append(\"\".join(groupOutput))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the output check OCR information to the screen\n",
    "print(\"Check OCR: {}\".format(\" \".join(output)))\n",
    "cv2.imshow(\"Check OCR\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract \n",
    "import cv2\n",
    "from PIL import Image \n",
    " \n",
    "value=cv2.imread(\"example1_250x250.jpg\") \n",
    "value = value[430:900, 250:900]\n",
    "# grayImage = cv2.cvtColor(value, cv2.COLOR_BGR2GRAY)\n",
    "text=pytesseract.image_to_string(value) \n",
    "# cv2.imshow(\"Group\", grayImage)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "# print(\"text present in images:\",text) \n",
    "img_gray = cv2.cvtColor(value, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# canny_edges = cv2.Canny(img_gray, 2000, 255)\n",
    "# img_gray_blur = cv2.GaussianBlur(img_gray, (1,1), 0)\n",
    "# ret,mask  = cv2.threshold(canny_edges, 70, 255, cv2.THRESH_BINARY_INV)\n",
    "cv2.imshow(\"Group\",img_gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "text = pytesseract.image_to_string(img_gray, lang = 'mcr')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pytesseract \n",
    " \n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "value=cv2.imread(\"example_250x250.jpg\") \n",
    "value = value[430:900, 250:900]\n",
    "# grayImage = cv2.cvtColor(value, cv2.COLOR_BGR2GRAY)\n",
    "hsv = cv2.cvtColor(value, cv2.COLOR_BGR2HSV) \n",
    "      \n",
    "# Threshold of blue in HSV space \n",
    "lower_blue = np.array([0, 0, 0]) \n",
    "upper_blue = np.array([150, 150, 150]) \n",
    "\n",
    "# preparing the mask to overlay \n",
    "mask = cv2.inRange(hsv, lower_blue, upper_blue) \n",
    "\n",
    "# The black region in the mask has the value of 0, \n",
    "# so when multiplied with original image removes all non-blue regions \n",
    "result = cv2.bitwise_and(value, value, mask = mask) \n",
    "# result = cv2.Canny(result, 254, 255)\n",
    "cv2.imshow(\"Group\",result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "text = pytesseract.image_to_string(result, lang = 'mcr')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "value=cv2.imread(\"example2_250x250.jpg\") \n",
    "value = value[430:900, 250:900]\n",
    "img = cv2.cvtColor(value, cv2.COLOR_BGR2GRAY)\n",
    "img = cv2.threshold(img, 0, 100, cv2.THRESH_OTSU | cv2.THRESH_BINARY)[1]\n",
    "cv2.imshow(\"Group\",value)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "text = pytesseract.image_to_string(value, lang = 'mcr')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
